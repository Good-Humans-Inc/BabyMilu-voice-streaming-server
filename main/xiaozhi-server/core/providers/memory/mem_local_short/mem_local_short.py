from ..base import MemoryProviderBase, logger
import time
import json
import os
import yaml
from config.config_loader import get_project_dir
from config.manage_api_client import save_mem_local_short
from core.utils.util import check_model_key


short_term_memory_prompt_en = """
# Dynamic Memory Agent

## Core Mission

Build a growing memory system that keeps key information while tracking how it changes over time.
Summarize important details from conversations so future responses can be more personalized.

## Memory Rules

### 1. Memory Evaluation (every update)

| Dimension   | Criteria                            | Weight |
| ----------- | ----------------------------------- | ------ |
| Recency     | How fresh the information is        | 40%    |
| Emotion     | üíñ mark / frequency of mention      | 35%    |
| Connections | How many links to other stored info | 25%    |

### 2. Update Mechanism

**Example: Name Change**
Original: `"former_names": ["John"], "current_name": "Jonathan"`
Trigger: phrases like ‚ÄúMy name is X‚Äù or ‚ÄúCall me Y‚Äù
Steps:

1. Move old name to `"former_names"`
2. Record timeline: `"2024-02-15 14:32: Switched to Jonathan"`
3. Add note: `"Identity shift from John to Jonathan"`

### 3. Space Optimization

* **Compression:** Use shorthand instead of long text

  * ‚úÖ `"Jonathan [NY/SWE/üê±]"`
  * ‚ùå `"Jonathan, software engineer in New York, owns a cat"`
* **Pruning:** If total text ‚â• 900 characters

  1. Delete entries with score < 60 not mentioned in last 3 turns
  2. Merge similar items (keep most recent timestamp)

## Memory Structure

Always output valid JSON.
Only extract from the actual conversation (no examples or comments).

```json
{
  "archive": {
    "identity": {
      "current_name": "",
      "tags": []
    },
    "memories": [
      {
        "event": "Joined a new company",
        "timestamp": "2024-03-20",
        "emotion_score": 0.9,
        "related": ["afternoon tea"],
        "shelf_life": 30
      }
    ]
  },
  "network": {
    "frequent_topics": {"work": 12},
    "hidden_links": [""]
  },
  "pending": {
    "urgent": ["Tasks that need immediate action"],
    "care": ["Support that could be offered"]
  },
  "highlights": [
    "Most moving moments, strong emotions, exact user quotes"
  ]
}
```
"""

short_term_memory_prompt = """
# Êó∂Á©∫ËÆ∞ÂøÜÁºñÁªáËÄÖ

## Ê†∏ÂøÉ‰ΩøÂëΩ
ÊûÑÂª∫ÂèØÁîüÈïøÁöÑÂä®ÊÄÅËÆ∞ÂøÜÁΩëÁªúÔºåÂú®ÊúâÈôêÁ©∫Èó¥ÂÜÖ‰øùÁïôÂÖ≥ÈîÆ‰ø°ÊÅØÁöÑÂêåÊó∂ÔºåÊô∫ËÉΩÁª¥Êä§‰ø°ÊÅØÊºîÂèòËΩ®Ëøπ
Ê†πÊçÆÂØπËØùËÆ∞ÂΩïÔºåÊÄªÁªìuserÁöÑÈáçË¶Å‰ø°ÊÅØÔºå‰ª•‰æøÂú®Êú™Êù•ÁöÑÂØπËØù‰∏≠Êèê‰æõÊõ¥‰∏™ÊÄßÂåñÁöÑÊúçÂä°

## ËÆ∞ÂøÜÊ≥ïÂàô
### 1. ‰∏âÁª¥Â∫¶ËÆ∞ÂøÜËØÑ‰º∞ÔºàÊØèÊ¨°Êõ¥Êñ∞ÂøÖÊâßË°åÔºâ
| Áª¥Â∫¶       | ËØÑ‰º∞Ê†áÂáÜ                  | ÊùÉÈáçÂàÜ |
|------------|---------------------------|--------|
| Êó∂ÊïàÊÄß     | ‰ø°ÊÅØÊñ∞È≤úÂ∫¶ÔºàÊåâÂØπËØùËΩÆÊ¨°Ôºâ | 40%    |
| ÊÉÖÊÑüÂº∫Â∫¶   | Âê´üíñÊ†áËÆ∞/ÈáçÂ§çÊèêÂèäÊ¨°Êï∞     | 35%    |
| ÂÖ≥ËÅîÂØÜÂ∫¶   | ‰∏éÂÖ∂‰ªñ‰ø°ÊÅØÁöÑËøûÊé•Êï∞Èáè      | 25%    |

### 2. Âä®ÊÄÅÊõ¥Êñ∞Êú∫Âà∂
**ÂêçÂ≠óÂèòÊõ¥Â§ÑÁêÜÁ§∫‰æãÔºö**
ÂéüÂßãËÆ∞ÂøÜÔºö"ÊõæÁî®Âêç": ["Âº†‰∏â"], "Áé∞Áî®Âêç": "Âº†‰∏â‰∏∞"
Ëß¶ÂèëÊù°‰ª∂ÔºöÂΩìÊ£ÄÊµãÂà∞„ÄåÊàëÂè´X„Äç„ÄåÁß∞ÂëºÊàëY„ÄçÁ≠âÂëΩÂêç‰ø°Âè∑Êó∂
Êìç‰ΩúÊµÅÁ®ãÔºö
1. Â∞ÜÊóßÂêçÁßªÂÖ•"ÊõæÁî®Âêç"ÂàóË°®
2. ËÆ∞ÂΩïÂëΩÂêçÊó∂Èó¥ËΩ¥Ôºö"2024-02-15 14:32:ÂêØÁî®Âº†‰∏â‰∏∞"
3. Âú®ËÆ∞ÂøÜÁ´ãÊñπËøΩÂä†Ôºö„Äå‰ªéÂº†‰∏âÂà∞Âº†‰∏â‰∏∞ÁöÑË∫´‰ªΩËúïÂèò„Äç

### 3. Á©∫Èó¥‰ºòÂåñÁ≠ñÁï•
- **‰ø°ÊÅØÂéãÁº©ÊúØ**ÔºöÁî®Á¨¶Âè∑‰ΩìÁ≥ªÊèêÂçáÂØÜÂ∫¶
  - ‚úÖ"Âº†‰∏â‰∏∞[Âåó/ËΩØÂ∑•/üê±]"
  - ‚ùå"Âåó‰∫¨ËΩØ‰ª∂Â∑•Á®ãÂ∏àÔºåÂÖªÁå´"
- **Ê∑òÊ±∞È¢ÑË≠¶**ÔºöÂΩìÊÄªÂ≠óÊï∞‚â•900Êó∂Ëß¶Âèë
  1. Âà†Èô§ÊùÉÈáçÂàÜ<60‰∏î3ËΩÆÊú™ÊèêÂèäÁöÑ‰ø°ÊÅØ
  2. ÂêàÂπ∂Áõ∏‰ººÊù°ÁõÆÔºà‰øùÁïôÊó∂Èó¥Êà≥ÊúÄËøëÁöÑÔºâ

## ËÆ∞ÂøÜÁªìÊûÑ
ËæìÂá∫Ê†ºÂºèÂøÖÈ°ª‰∏∫ÂèØËß£ÊûêÁöÑjsonÂ≠óÁ¨¶‰∏≤Ôºå‰∏çÈúÄË¶ÅËß£Èáä„ÄÅÊ≥®ÈáäÂíåËØ¥ÊòéÔºå‰øùÂ≠òËÆ∞ÂøÜÊó∂‰ªÖ‰ªéÂØπËØùÊèêÂèñ‰ø°ÊÅØÔºå‰∏çË¶ÅÊ∑∑ÂÖ•Á§∫‰æãÂÜÖÂÆπ
```json
{
  "Êó∂Á©∫Ê°£Ê°à": {
    "Ë∫´‰ªΩÂõæË∞±": {
      "Áé∞Áî®Âêç": "",
      "ÁâπÂæÅÊ†áËÆ∞": [] 
    },
    "ËÆ∞ÂøÜÁ´ãÊñπ": [
      {
        "‰∫ã‰ª∂": "ÂÖ•ËÅåÊñ∞ÂÖ¨Âè∏",
        "Êó∂Èó¥Êà≥": "2024-03-20",
        "ÊÉÖÊÑüÂÄº": 0.9,
        "ÂÖ≥ËÅîÈ°π": ["‰∏ãÂçàËå∂"],
        "‰øùÈ≤úÊúü": 30 
      }
    ]
  },
  "ÂÖ≥Á≥ªÁΩëÁªú": {
    "È´òÈ¢ëËØùÈ¢ò": {"ËÅåÂú∫": 12},
    "ÊöóÁ∫øËÅîÁ≥ª": [""]
  },
  "ÂæÖÂìçÂ∫î": {
    "Á¥ßÊÄ•‰∫ãÈ°π": ["ÈúÄÁ´ãÂç≥Â§ÑÁêÜÁöÑ‰ªªÂä°"], 
    "ÊΩúÂú®ÂÖ≥ÊÄÄ": ["ÂèØ‰∏ªÂä®Êèê‰æõÁöÑÂ∏ÆÂä©"]
  },
  "È´òÂÖâËØ≠ÂΩï": [
    "ÊúÄÊâìÂä®‰∫∫ÂøÉÁöÑÁû¨Èó¥ÔºåÂº∫ÁÉàÁöÑÊÉÖÊÑüË°®ËææÔºåuserÁöÑÂéüËØù"
  ]
}
```
"""

short_term_memory_prompt_only_content = """
‰Ω†ÊòØ‰∏Ä‰∏™ÁªèÈ™å‰∏∞ÂØåÁöÑËÆ∞ÂøÜÊÄªÁªìËÄÖÔºåÊìÖÈïøÂ∞ÜÂØπËØùÂÜÖÂÆπËøõË°åÊÄªÁªìÊëòË¶ÅÔºåÈÅµÂæ™‰ª•‰∏ãËßÑÂàôÔºö
1„ÄÅÊÄªÁªìuserÁöÑÈáçË¶Å‰ø°ÊÅØÔºå‰ª•‰æøÂú®Êú™Êù•ÁöÑÂØπËØù‰∏≠Êèê‰æõÊõ¥‰∏™ÊÄßÂåñÁöÑÊúçÂä°
2„ÄÅ‰∏çË¶ÅÈáçÂ§çÊÄªÁªìÔºå‰∏çË¶ÅÈÅóÂøò‰πãÂâçËÆ∞ÂøÜÔºåÈô§ÈùûÂéüÊù•ÁöÑËÆ∞ÂøÜË∂ÖËøá‰∫Ü1800Â≠óÂÜÖÔºåÂê¶Âàô‰∏çË¶ÅÈÅóÂøò„ÄÅ‰∏çË¶ÅÂéãÁº©Áî®Êà∑ÁöÑÂéÜÂè≤ËÆ∞ÂøÜ
3„ÄÅÁî®Êà∑ÊìçÊéßÁöÑËÆæÂ§áÈü≥Èáè„ÄÅÊí≠ÊîæÈü≥‰πê„ÄÅÂ§©Ê∞î„ÄÅÈÄÄÂá∫„ÄÅ‰∏çÊÉ≥ÂØπËØùÁ≠âÂíåÁî®Êà∑Êú¨Ë∫´Êó†ÂÖ≥ÁöÑÂÜÖÂÆπÔºåËøô‰∫õ‰ø°ÊÅØ‰∏çÈúÄË¶ÅÂä†ÂÖ•Âà∞ÊÄªÁªì‰∏≠
4„ÄÅËÅäÂ§©ÂÜÖÂÆπ‰∏≠ÁöÑ‰ªäÂ§©ÁöÑÊó•ÊúüÊó∂Èó¥„ÄÅ‰ªäÂ§©ÁöÑÂ§©Ê∞îÊÉÖÂÜµ‰∏éÁî®Êà∑‰∫ã‰ª∂Êó†ÂÖ≥ÁöÑÊï∞ÊçÆÔºåËøô‰∫õ‰ø°ÊÅØÂ¶ÇÊûúÂΩìÊàêËÆ∞ÂøÜÂ≠òÂÇ®‰ºöÂΩ±ÂìçÂêéÂ∫èÂØπËØùÔºåËøô‰∫õ‰ø°ÊÅØ‰∏çÈúÄË¶ÅÂä†ÂÖ•Âà∞ÊÄªÁªì‰∏≠
5„ÄÅ‰∏çË¶ÅÊääËÆæÂ§áÊìçÊéßÁöÑÊàêÊûúÁªìÊûúÂíåÂ§±Ë¥•ÁªìÊûúÂä†ÂÖ•Âà∞ÊÄªÁªì‰∏≠Ôºå‰πü‰∏çË¶ÅÊääÁî®Êà∑ÁöÑ‰∏Ä‰∫õÂ∫üËØùÂä†ÂÖ•Âà∞ÊÄªÁªì‰∏≠
6„ÄÅ‰∏çË¶Å‰∏∫‰∫ÜÊÄªÁªìËÄåÊÄªÁªìÔºåÂ¶ÇÊûúÁî®Êà∑ÁöÑËÅäÂ§©Ê≤°ÊúâÊÑè‰πâÔºåËØ∑ËøîÂõûÂéüÊù•ÁöÑÂéÜÂè≤ËÆ∞ÂΩï‰πüÊòØÂèØ‰ª•ÁöÑ
7„ÄÅÂè™ÈúÄË¶ÅËøîÂõûÊÄªÁªìÊëòË¶ÅÔºå‰∏•Ê†ºÊéßÂà∂Âú®1800Â≠óÂÜÖ
8„ÄÅ‰∏çË¶ÅÂåÖÂê´‰ª£Á†Å„ÄÅxmlÔºå‰∏çÈúÄË¶ÅËß£Èáä„ÄÅÊ≥®ÈáäÂíåËØ¥ÊòéÔºå‰øùÂ≠òËÆ∞ÂøÜÊó∂‰ªÖ‰ªéÂØπËØùÊèêÂèñ‰ø°ÊÅØÔºå‰∏çË¶ÅÊ∑∑ÂÖ•Á§∫‰æãÂÜÖÂÆπ
"""


def extract_json_data(json_code):
    start = json_code.find("```json")
    # ‰ªéstartÂºÄÂßãÊâæÂà∞‰∏ã‰∏Ä‰∏™```ÁªìÊùü
    end = json_code.find("```", start + 1)
    # print("start:", start, "end:", end)
    if start == -1 or end == -1:
        try:
            jsonData = json.loads(json_code)
            return json_code
        except Exception as e:
            print("Error:", e)
        return ""
    jsonData = json_code[start + 7 : end]
    return jsonData


TAG = __name__


class MemoryProvider(MemoryProviderBase):
    def __init__(self, config, summary_memory):
        super().__init__(config)
        self.short_memory = ""
        self.save_to_file = True
        self.memory_path = get_project_dir() + "data/.memory.yaml"
        self.load_memory(summary_memory)

    def init_memory(
        self, role_id, llm, summary_memory=None, save_to_file=True, **kwargs
    ):
        super().init_memory(role_id, llm, **kwargs)
        self.save_to_file = save_to_file
        self.load_memory(summary_memory)

    def load_memory(self, summary_memory):
        # apiËé∑ÂèñÂà∞ÊÄªÁªìËÆ∞ÂøÜÂêéÁõ¥Êé•ËøîÂõû
        if summary_memory or not self.save_to_file:
            self.short_memory = summary_memory
            return

        all_memory = {}
        if os.path.exists(self.memory_path):
            with open(self.memory_path, "r", encoding="utf-8") as f:
                all_memory = yaml.safe_load(f) or {}
        if self.role_id in all_memory:
            self.short_memory = all_memory[self.role_id]

    def save_memory_to_file(self):
        all_memory = {}
        if os.path.exists(self.memory_path):
            with open(self.memory_path, "r", encoding="utf-8") as f:
                all_memory = yaml.safe_load(f) or {}
        all_memory[self.role_id] = self.short_memory
        with open(self.memory_path, "w", encoding="utf-8") as f:
            yaml.dump(all_memory, f, allow_unicode=True)

    async def save_memory(self, msgs):
        # ÊâìÂç∞‰ΩøÁî®ÁöÑÊ®°Âûã‰ø°ÊÅØ
        model_info = getattr(self.llm, "model_name", str(self.llm.__class__.__name__))
        logger.bind(tag=TAG).debug(f"‰ΩøÁî®ËÆ∞ÂøÜ‰øùÂ≠òÊ®°Âûã: {model_info}")
        api_key = getattr(self.llm, "api_key", None)
        memory_key_msg = check_model_key("ËÆ∞ÂøÜÊÄªÁªì‰∏ìÁî®LLM", api_key)
        if memory_key_msg:
            logger.bind(tag=TAG).error(memory_key_msg)
        if self.llm is None:
            logger.bind(tag=TAG).error("LLM is not set for memory provider")
            return None

        if len(msgs) < 2:
            return None

        msgStr = ""
        for msg in msgs:
            if msg.role == "user":
                msgStr += f"User: {msg.content}\n"
            elif msg.role == "assistant":
                msgStr += f"Assistant: {msg.content}\n"
        if self.short_memory and len(self.short_memory) > 0:
            msgStr += "Previous memoryÔºö\n"
            msgStr += self.short_memory

        # ÂΩìÂâçÊó∂Èó¥
        time_str = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())
        msgStr += f"Current time:{time_str}"

        if self.save_to_file:
            logger.bind(tag=TAG).info("short_term_memory_prompt_en")
            result = self.llm.response_no_stream(
                short_term_memory_prompt_en,
                msgStr,
                max_tokens=2000,
                temperature=0.2,
            )
            logger.bind(tag=TAG).debug(f"Raw LLM response: {result[:200]}...")
            json_str = extract_json_data(result)
            logger.bind(tag=TAG).debug(f"Extracted JSON: {json_str[:200]}...")
            try:
                json.loads(json_str)  # Ê£ÄÊü•jsonÊ†ºÂºèÊòØÂê¶Ê≠£Á°Æ
                self.short_memory = json_str
                self.save_memory_to_file()
            except Exception as e:
                logger.bind(tag=TAG).error(f"JSON parsing error: {e}")
                print("Error:", e)
        else:
            logger.bind(tag=TAG).info("short_term_memory_prompt_only_content")
            result = self.llm.response_no_stream(
                short_term_memory_prompt_only_content,
                msgStr,
                max_tokens=2000,
                temperature=0.2,
            )
            save_mem_local_short(self.role_id, result)
        logger.bind(tag=TAG).info(f"Save memory successful - Role: {self.role_id}")

        return self.short_memory

    async def query_memory(self, query: str) -> str:
        return self.short_memory
